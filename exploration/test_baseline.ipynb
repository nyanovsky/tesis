{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch, torch_geometric\n",
    "from models import training_utils, prediction_utils, exp_utils, mlp_baseline\n",
    "from exploration import explor_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"/biodata/nyanovsky/datasets/dti/processed/v2/\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "node_df = pd.read_csv(data_folder+\"dti_tensor_df.csv\",index_col=0)\n",
    "#load data\n",
    "datasets, node_map = training_utils.load_data(data_folder,load_inverted_map=False,load_test=True)\n",
    "\n",
    "train_set, val_set, test_set = datasets\n",
    "\n",
    "gene_feature_dict = training_utils.load_feature_dict(data_folder+\"prot_features_64.txt\", data_folder+\"prot_features_ids.txt\", \n",
    "                                                    node_df, \"gene\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "configs_folder = \"/biodata/nyanovsky/datasets/dti/best_models/\"\n",
    "with open(configs_folder+\"sage_config.yaml\",\"r\") as file:\n",
    "    sage_config = yaml.safe_load(file)\n",
    "train_params = sage_config[\"train\"]\n",
    "gral_params = sage_config[\"gral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L2_norm': False,\n",
       " 'batch_norm': False,\n",
       " 'dropout': 0.0,\n",
       " 'hidden_channels': 32,\n",
       " 'layer_connectivity': 'False',\n",
       " 'macro_aggregation': 'sum',\n",
       " 'msg_passing_layers': 4,\n",
       " 'normalize_output': False,\n",
       " 'post_process_layers': 0,\n",
       " 'pre_process_layers': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gral_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/users/nyanovsky/tesis/exploration/../models/training_utils.py:134: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  data_object[nodetype].x[tensor_idxs] = nodetype_embs\n"
     ]
    }
   ],
   "source": [
    "train, val, test = exp_utils.init_features(train_set,val_set,test_set, train_params, gene_feature_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = mlp_baseline.MLP_model(params={\"hidden_channels\":32, \"batch_norm\":False, \"dropout\":0.0, \"post_process_layers\":4},\n",
    "                             metadata=train_set.metadata(), sup_type=[(\"gene\",\"chg\",\"chem\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "versiones = [\"v2\",\"v_test/seed_0\",\"v_test/seed_1\", \"v_test/seed_2\", \"v_test/seed_3\", \"v_test/seed_4\",\n",
    "             \"v_test/seed_5\", \"v_test/seed_6\", \"v_test/seed_7\", \"v_test/seed_8\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_set = torch.load(data_folder+\"dti_full_dataset.pt\")\n",
    "negative_sampler = training_utils.NegativeSampler(full_set,(\"gene\",\"chg\",\"chem\"),full_set[\"gene\"][\"degree_chg\"],full_set[\"chem\"][\"degree_chg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v2 done\n",
      "\n",
      "v_test/seed_0 done\n",
      "\n",
      "v_test/seed_1 done\n",
      "\n",
      "v_test/seed_2 done\n",
      "\n",
      "v_test/seed_3 done\n",
      "\n",
      "v_test/seed_4 done\n",
      "\n",
      "v_test/seed_5 done\n",
      "\n",
      "v_test/seed_6 done\n",
      "\n",
      "v_test/seed_7 done\n",
      "\n",
      "v_test/seed_8 done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "perf = {\"auc\":[], \"acc\":[], \"ap\":[],\"precision\":[], \"recall\":[]}\n",
    "for version in versiones:\n",
    "    data_folder = f\"/biodata/nyanovsky/datasets/dti/processed/{version}/\"\n",
    "    dataset, node_map = training_utils.load_data(data_folder,load_inverted_map=False,load_test=True)\n",
    "    node_df = pd.read_csv(data_folder+\"dti_tensor_df.csv\",index_col=0)\n",
    "    full_set = torch.load(data_folder+\"dti_full_dataset.pt\")\n",
    "    negative_sampler = training_utils.NegativeSampler(full_set,(\"gene\",\"chg\",\"chem\"),full_set[\"gene\"][\"degree_chg\"],full_set[\"chem\"][\"degree_chg\"])\n",
    "    train, val, test = exp_utils.init_features(dataset[0], dataset[1], dataset[2], train_params, gene_feature_dict)\n",
    "    model = exp_utils.train_model(mlp, train_params, train, val, negative_sampler)[0]\n",
    "    model = model.to(\"cpu\")\n",
    "    encodings = model.encoder(test.x_dict)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictor = prediction_utils.Predictor(node_df,encodings)\n",
    "        preds = predictor.predict_supervision_edges(test,(\"gene\",\"chg\",\"chem\"))\n",
    "        y_true = preds.label.values\n",
    "        y_score = preds.score.values\n",
    "        y_pred_labels = preds.score.values.round()\n",
    "\n",
    "        auc = roc_auc_score(y_true,y_score)\n",
    "        acc = accuracy_score(y_true,y_pred_labels) \n",
    "        ap = average_precision_score(y_true,y_score) \n",
    "        precision = precision_score(y_true,y_pred_labels) \n",
    "        recall = recall_score(y_true,y_pred_labels) \n",
    "\n",
    "        perf[\"auc\"].append(auc)\n",
    "        perf[\"acc\"].append(acc)\n",
    "        perf[\"ap\"].append(ap)\n",
    "        perf[\"precision\"].append(precision)\n",
    "        perf[\"recall\"].append(recall)\n",
    "    print(version + \" done\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean auc = 0.5756983634258861 $\\pm$ 0.009152883052088586\n",
      "mean acc = 0.5542589215941651 $\\pm$ 0.007088625182493206\n",
      "mean ap = 0.5749191926584549 $\\pm$ 0.007135015422395094\n",
      "mean precision = 0.561170433011522 $\\pm$ 0.009441659393076358\n",
      "mean recall = 0.5031518624641833 $\\pm$ 0.05523539298195471\n"
     ]
    }
   ],
   "source": [
    "for key in perf.keys():\n",
    "    print(f\"mean {key} = {np.mean(perf[key])} $\\pm$ {np.std(perf[key])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
